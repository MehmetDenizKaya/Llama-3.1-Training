# Llama-3.1-Training
This repo includes training 67k row data for LLama 3.1 with 8b parameter, using Google Collab and Unsloth tools
